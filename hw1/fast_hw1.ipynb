{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069c3495",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from time import time\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "def AveP(pred, ans):\n",
    "    is_relevence = np.array([1 if p in ans else 0 for p in pred])\n",
    "    return ((np.arange(sum(is_relevence))+1) / (np.where(is_relevence > 0)[0]+1)).sum() / min(100, len(ans))\n",
    "\n",
    "def read_query(filepath):\n",
    "    tree = ET.parse(filepath)\n",
    "    questions = []\n",
    "    for p in tree.findall('topic'):\n",
    "        questions.append([x.text.strip() for x in p.findall('*')])\n",
    "    return questions\n",
    "\n",
    "def query_processing(questions):\n",
    "    def parse(words):\n",
    "        uni = np.array(reduce(np.union1d, [list(x) for x in words]))\n",
    "        bi = np.array(reduce(np.union1d, [word[i:i+2] for word in words for i in range(len(word)-1)]))\n",
    "        return uni.tolist(), bi.tolist()\n",
    "    \n",
    "    res = []\n",
    "    for q in questions:\n",
    "        concepts = parse(q[-1][:-1].split('ã€'))\n",
    "        title = parse([q[1]])\n",
    "        res.append((concepts, title))\n",
    "    return res\n",
    "\n",
    "def open_file(path):\n",
    "    tree = ET.parse(path.strip())\n",
    "    id_ = tree.find('.//id').text\n",
    "    text = ''.join([x.text.strip() for x in tree.findall('.//p')])\n",
    "    return id_, text\n",
    "    \n",
    "def BM25_score(d, weight, terms, cand, k1=1.2, b=0.75):\n",
    "    tf = d.t2d[terms, :][:, cand].toarray()\n",
    "    return (weight*d.idf[terms]).dot((tf*(k1 + 1))/(tf + k1*(1 - b + b*(d.docs_length[cand] / d.avg_length))))\n",
    "\n",
    "def get_result_list(q_id, filelist, res):\n",
    "    return [q_id[-3:], ' '.join([open_file(filelist[i])[0].lower() for i in res])]\n",
    "\n",
    "def query_extractor(d, terms, return_filter=True):\n",
    "    uni, bi = terms\n",
    "    bi = np.setdiff1d(bi, d.black_list).tolist()\n",
    "    query_terms = [d.vocabs_dict[x] for x in uni+bi]\n",
    "    if return_filter:\n",
    "        return query_terms, np.ones(len(query_terms)), bi\n",
    "    return query_terms, np.ones(len(query_terms))\n",
    "\n",
    "def search(scores, cand, num=100):\n",
    "    rank = np.argsort(scores)\n",
    "    res = cand[rank[-num:]][::-1]\n",
    "    return rank, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dedfb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, model_path, ntcir_path):        \n",
    "        self.filelist = []\n",
    "        \n",
    "        self.docs_length = np.zeros(0)\n",
    "        self.avg_length = 0\n",
    "        self.num_docs = 0\n",
    "        \n",
    "        self.vocabs_dict = {}\n",
    "        self.black_list = []\n",
    "        self.idf = np.zeros(0)\n",
    "        self.t2d = None\n",
    "        \n",
    "        self.start = 0\n",
    "        self.model_path = model_path\n",
    "        self.ntcir_path = ntcir_path\n",
    "        \n",
    "    def get_docs_length(self):\n",
    "        with open(join(self.model_path, 'file-list')) as f:\n",
    "            self.filelist = [join(self.ntcir_path, s.strip()) for s in f.readlines()]\n",
    "            for file_path in self.filelist:\n",
    "                tree = ET.parse(file_path)\n",
    "                text = ''.join([x.text.strip() for x in tree.findall('.//p')])\n",
    "                chinese_text = re.findall(r\"[\\u4e00-\\u9fa5']+\", text)\n",
    "                self.docs_length = np.r_[self.docs_length, np.sum([len(x) for x in chinese_text])]\n",
    "        self.avg_length = np.mean(self.docs_length)\n",
    "        self.num_docs = len(self.docs_length)\n",
    "    \n",
    "    def dump_time(self, slogan):\n",
    "        print(slogan+', total time: %06.2f sec.' % (time() - self.start))\n",
    "\n",
    "    def build(self, corpus):\n",
    "        self.start = time()\n",
    "        self.get_docs_length()\n",
    "        self.dump_time('Finish getting documents length')\n",
    "        \n",
    "        # Read inverted-file\n",
    "        all_term = pd.read_csv(join(self.model_path, 'inverted-file'), delimiter=' ', header=None, usecols=[0,1,2]).values\n",
    "        # Get the indices of lines with 3 digits\n",
    "        indices = np.where(~np.isnan(all_term[:, 2]))[0]\n",
    "        \n",
    "        self.dump_time('Finish reading inverted file')\n",
    "        \n",
    "        # Read vocab.all\n",
    "        char = pd.read_csv(join(self.model_path, 'vocab.all'), header=None, index_col=False, delimiter='\\n', quoting=3, encoding='utf-8').values.reshape(-1)\n",
    "        char_dict = dict(zip(char, np.arange(len(char), dtype=int)))\n",
    "        \n",
    "        self.dump_time('Finish reading vocabulary file')\n",
    "        \n",
    "        terms = [(char_dict[x[0]], char_dict[x[1]]) if len(x) > 1 else (char_dict[x[0]], -1) for x in corpus]\n",
    "        terms = sorted(terms, key=lambda t: (t[0], t[1]))\n",
    "        i = 0\n",
    "        row, col, data = [], [], []\n",
    "        for t1, t2 in terms:\n",
    "            w = char[t1] + char[t2] if t2 > 0 else char[t1]\n",
    "            for move, idx in enumerate(indices[i:]):\n",
    "                # Find the term\n",
    "                if all_term[idx][0] == t1 and all_term[idx][1] == t2:\n",
    "                    # Add the term to vocabs_dict\n",
    "                    self.vocabs_dict[w] = len(self.vocabs_dict)\n",
    "\n",
    "                    nqi = all_term[idx][2]\n",
    "                    self.idf = np.r_[self.idf, np.log((self.num_docs - nqi + 0.5)/(nqi + 0.5) + 1)]\n",
    "                    interval = all_term[idx+1:indices[i+move+1]].astype(int)\n",
    "\n",
    "                    row += [len(self.vocabs_dict)-1]*len(interval)\n",
    "                    col += interval[:, 0].tolist()\n",
    "                    data += interval[:, 1].tolist()\n",
    "                    break\n",
    "                    \n",
    "                # The term doesn't exist in inverted-file\n",
    "                elif all_term[idx][0] > t1:\n",
    "                    self.black_list.append(w)\n",
    "                    break\n",
    "            i += move\n",
    "            print('Processing ... %06.2f%%, total time: %06.2f sec.' % (100*(i+1)/len(indices), time() - self.start), end='\\r')\n",
    "        self.t2d = csr_matrix((data, (row, col)), shape=(len(self.idf), self.num_docs))\n",
    "        self.dump_time('\\nFinish building dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0df915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self, query_file, output_file, model_path, nctir_path, answer_path=None, relevence=False):\n",
    "        self.query_file = query_file\n",
    "        self.output_file = output_file\n",
    "        self.model_path = model_path\n",
    "        self.nctir_path = nctir_path\n",
    "        self.answer_path = answer_path\n",
    "        self.relevence = relevence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb36ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish getting documents length, total time: 020.73 sec.\n",
      "Finish reading inverted file, total time: 035.85 sec.\n",
      "Finish reading vocabulary file, total time: 035.87 sec.\n",
      "Processing ... 097.16%, total time: 037.58 sec.\n",
      "Finish building dataset, total time: 039.12 sec.\n",
      "Processing 20 / 20, total time: 040.42 sec.\n",
      "Finish, total time: 040.52 sec.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time()\n",
    "    args = Args('/tmp2/r09922104/ir/queries/query-test.xml', './output.csv', \n",
    "                '/tmp2/r09922104/ir/model', '/tmp2/r09922104/ir/CIRB010',\n",
    "#                 '/tmp2/r09922104/ir/queries/ans_train.csv', relevence=False)\n",
    "                relevence=False)\n",
    "    \n",
    "    if args.answer_path:\n",
    "        answer = [x.split() for x in pd.read_csv(args.answer_path)['retrieved_docs'].tolist()]\n",
    "        \n",
    "    questions = read_query(args.query_file)\n",
    "    queries = query_processing(questions)\n",
    "    corpus = reduce(np.union1d, [x[0]+x[1]+y[0]+y[1] for x, y in queries]).tolist()\n",
    "\n",
    "    d = Dataset(args.model_path, args.nctir_path)\n",
    "    d.build(corpus)\n",
    "    \n",
    "    result = []\n",
    "    if args.answer_path:\n",
    "        MAP, MRP = [], []\n",
    "\n",
    "    # Parameters of relevence feedback\n",
    "    num_iter = 1 if not args.relevence else 5\n",
    "    num_related, alpha = 5, 0.98\n",
    "\n",
    "    if args.relevence:\n",
    "        print('Start Relevence Feedback Mode, num_iter: %d, num_related: %d, alpha: %.2f' %(num_iter, num_related, alpha))\n",
    "\n",
    "    for _, query in enumerate(queries):\n",
    "        print('Processing %02d / %02d, total time: %06.2f sec.' % (_+1, len(queries), time() - start), end='\\r')\n",
    "\n",
    "        concepts, title = query\n",
    "        query_terms, query_weight, filters = query_extractor(d, concepts, return_filter=True)\n",
    "        candidates = reduce(np.union1d, [d.t2d[d.vocabs_dict[x]].nonzero() for x in filters])\n",
    "\n",
    "        for __ in range(num_iter):\n",
    "            cscores = BM25_score(d, query_weight, query_terms, candidates)\n",
    "            crank, cres = search(cscores, candidates)\n",
    "            related_weight = d.t2d[query_terms, :][:, cres[:num_related]].toarray().mean(axis=-1)\n",
    "            query_weight = alpha * query_weight + (1 - alpha) * related_weight\n",
    "\n",
    "        # Using title to further improve accuracy\n",
    "        t_query_terms, t_query_weight = query_extractor(d, title, return_filter=False)\n",
    "        candidates = candidates[crank[-2000:]]\n",
    "        tscores = BM25_score(d, t_query_weight, t_query_terms, candidates)\n",
    "\n",
    "        # Mix the results from concepts, and from title\n",
    "        beta = 0.5\n",
    "        scores = beta * cscores[crank[-2000:]] + (1-beta) * tscores\n",
    "        rank, res = search(scores, candidates)\n",
    "\n",
    "        result.append(get_result_list(questions[_][0], d.filelist, res))\n",
    "\n",
    "        if args.answer_path:\n",
    "            MAP.append(AveP(result[-1][1].split(), answer[_]))\n",
    "            recall = np.sum([1 if r in answer[_] else 0 for r in result[-1][1].split()[:30]])\n",
    "            MRP.append(recall / len(answer[_]))\n",
    "\n",
    "    pd.DataFrame(result).to_csv(args.output_file, header=['query_id','retrieved_docs'], index=False)\n",
    "    print('\\nFinish, total time: %06.2f sec.' % (time() - start))\n",
    "\n",
    "    if args.answer_path:\n",
    "        print('MAP@100: %.5f' % (np.mean(MAP)))\n",
    "        print('MRP: %.5f' % (np.mean(MRP)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
